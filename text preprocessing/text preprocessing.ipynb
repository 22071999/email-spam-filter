{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import sqlite3    ## SQL Interface\n",
    "import pickle     ## Used to save your data - Converts objects to byte stream and vice versa\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emails</th>\n",
       "      <th>lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slur . . . mean , sir : armey 's slip slip , s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>across mail 12 re : punctuation . email punctu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject : begin begin begin groundfloor someth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nice true democracy try reach agreement phonet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>read research literature slip tongue scan both...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Emails  lable\n",
       "0  slur . . . mean , sir : armey 's slip slip , s...      1\n",
       "1  across mail 12 re : punctuation . email punctu...      1\n",
       "2  subject : begin begin begin groundfloor someth...      0\n",
       "3  nice true democracy try reach agreement phonet...      1\n",
       "4  read research literature slip tongue scan both...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('Emails.sqlite')\n",
    "\n",
    "final = pd.read_sql_query(\"\"\"SELECT * FROM Emails\"\"\", conn)\n",
    "\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indiana university linguistics club publications : two classics reissued phonology wilbur , ronnie . phonology reduplication . since appearance work 1973 , continual theoretical significance . wilbur document case under - over-application rule reduplicative form problem present rule order . foreshadow current work optimality theory reject rule order develop notion akin reduplicative base - reduplicant identity . work play important role rule order debate 1970 , development reduplication theory within prosodic morphology during 1980 , currently provide insight emerge correspondence theory . copy * limit * . special reissue price : $ 6 . 50 humor tiersma , peter m . language-based humor marx brothers films tiersma 's popular essay excellent introduction linguistic analysis humor . using lexical semantics pragmatic , sound , yet lively , analysis specific example . great resource introductory linguistics course , read . price : $ 4 . 0 iulc publication , 720 e . atwater ave . , bloomington , 47401 . prepay order u . s . check money order . postage & handle one both : add $ 3 . 50 ( us order ) , $ 5 . 0 ( ) , $ 5 . 50 ( ) . < iulc @ indiana . edu > http : / / ezinfo . uc . indiana . edu / ~ iulc /\n",
      " \n",
      "\n",
      "\n",
      "hi - post query while ago non - english name anglicize . response quite interest , though most anecdotal , responder themselve note . most research cite sociolinguistic speech technology . still interest topic work . case , ' m include response , thanks apology typographical irregularity - best , larry rosenwald , wellesley college 1 ) > margaret lueb < malueb @ umich . edu > message linguist list want share story ( probably scholarly enough summary , though ) . name german spell \" lueb \" . alway assume pronounce \" lube \" pretty close expect german pronunciation ( though great-grandparent ; below ) . instead , irritatingly enough , \" lebb \" . story ' ve tell ( partly apocryphal ) grandfather ( first 12 sibling off farm parent settle 1880 's ) arrive university nebraska 1910 , professor german department ask \" american pronunciation name ? \" ( till family pronounce old - - speak german home live among lot german ) . professor , reason , \" lebb \" 's stick . few later another brother university , * * * different * professor german department ask same question . answer \" leeb \" 's descendant pronounce name . cousin seem own common sense , pronounce \" lube \" . however old letter germany address great-grandfather , refer \" h . lib \" , ( misspell perhap inspire actual pronunciation ) original pronunciation closer \" leeb \" . still n't explain \" lebb \" , oh . n't ask - - 's phonetic factor even normal sociolinguistic one , rather dread influence university professor ! 2 ) > lexo @ lsus . sel . sony . com ( lex olorenshaw ) hi , anglicization topic interest , too , speech technology point view . example , anticipate anglicize pronunciation name order produce better synthesize speech , automatically recognize speech better ? research area text - - speech synthesizer . n't too much . couple reference \" name pronunciation \" web site serve start point - http : / / www . bellcore . com / orator / oref . html since ' ve wonder , quick search \" name pronunciation \" linguistic abstract online ( currently free trial basis ! ) , follow item - - - - - - - - - - - title : variant grapheme-phoneme correspondence unfamiliar polysyllabic word author : robert l . trammell journal : language speech vol : 33 ( 4 ) , 1990 , 293-323 subdiscipline : phonology abstract : ten college student ten phds read aloud 30 unfamiliar english word , two five syllable length , greek , latin , germanic origin . average number different subject pronunciation per word five ( range one ten ) . each response compare rule-predict , dictionary-prescribe , most frequent pronunciation word . subject agree each dictionary , latter rule . however , rule predict half prescribe pronunciation , better average number individual subject ` s response agree dictionary . most frequent response each word demonstrate considerably agreement both dictionary rule average number response subject individually . etymological source test word effect . while phds group significantly better student most measure , difference small . view previous research , frequent vowel lax open third fourth syllable end unexpect . several model read examine light result . - - - - - - - - - title : novel - word pronunciation : cross-language study author : k . p . h sullivan & r . . damper journal : speech communication vol : 13 ( 3 - 4 ) , 1993 , 441-452 subdiscipline : computational linguistic abstract : case ' novel word ' absent text-to - speech system ` s pronounce dictionary , traditional system invoke context-dependent letter-to - phoneme rule produce pronunciation . proposal psychological literature , however , human reader pronounce novel word explicit rule , analogy letter-to - phoneme pattern words already . paper , synthesis-by - analogy system present , accordingly , model novel-word pronunciation human . employ analogy both orthographic phonological domain apply here pronunciation novel word british ( receive pronunciation ) english german . implement system , certain detail question confront analogy theory present inadequately develop answer . thus , major part work concern impact implementational choice performance , where define ability system produce pronunciation line those human . size content lexical database analogy system must base consider . better perform implementation produce useful result both british english german . however , best result each two language obtain rather different implementation . author abstract : author - - - - - - - - - - - 3 )\n",
      " \n",
      "\n",
      "\n",
      "john phillip ( 8 . 859 ) ask , respect apostrophise plural , e . g . \" dyslexic 's \" , \" sonata 's \" , < < exactly grounds condemn usage ? > > one joy linguistlist here question ask , academic address . , , benjus wald perceptively remark , ebonic debate , linguist , linguist , believe equal value language form . perhap widen question \" grounds condemn particular variation human symbolic behaviour ( vocabulary , accent , spell , non - si unit , facial hair , clothe , tie untie lace ) ? \" ala , answer universalistic , down one two tyrannical reason : ' ll harm job prospects ; , even tyrannical : peer fun . depend reference group ( \" whom \" american reader ) , much feel fight . lot academic linguist fact neutral issue - - want sort compensatory justice usage disadvantage group , \" threaten language \" biologist colleague ' \" threaten species \" . ( , course , self-serve moral reason . ) explain gulf incomprehension between . hard common grind between those believe \" better oneself \" those invidious rubbish . roger depledge freelance translator toulouse\n",
      " \n",
      "\n",
      "\n",
      "sat , 3 jun 1995 , linguist list write : > deat : sat , 3 jun 1995 1 : 37 : 59 - 320 > : linguist list < linguist @ tam2000 . tamu . edu > > : hmander @ indiana . edu > subject : forward mail > > > stampe @ uhunix . uhcc . hawaius . edu frus jun 2 14 : 2 : 50 1995 > return - path : stampe @ uhunix . uhcc . hawaius . edu > receive : relay1 . hawaius . edu ( relay1 . hawaius . edu [ 128 . 171 . 41 . 53 ] ) tam20 0 . tamu . edu ( 8 . 6 . 12 / 8 . 6 . 12 ) smtp id oaa16738 < linguist @ tam2000 . tamu . ed u > ; frus , 2 jun 1995 14 : 2 : 47 - 320 > receive : uhunix3 . uhcc . hawaius . edu ( [ 128 . 171 . 44 . 52 ] ) relay1 . hawaius . edu smtp id < 11438 ( 5 ) > ; frus , 2 jun 1995 3 : 0 : 10 - 1000 > receive : uhunix3 . uhcc . hawaius . edu id < 148528 > ; frus , 2 jun 1995 09 : 0 : 29 - 1 0 > : david stampe < stampe @ uhunix . uhcc . hawaius . edu > > : linguist @ tam2000 . tamu . edu > - reply-to : < 199506021008 . faa11257 @ tam2000 . tamu . edu > ( message lingu ist list frus , 2 jun 1995 0 : 08 : 49 - 1000 ) > subject : re : 6 . 758 , sum : synthetic compound > message - id : < 95jun2 . 090029hst . 148528 @ uhunix3 . uhcc . hawaius . edu > > deat : frus , 2 jun 1995 08 : 59 : 51 - 1000 > status : ro > content - length : 1036 > > heather marie anderson ( hmander @ indiana . edu ) compare agentive > compound choose between ( 1 ) theory \" surface form > synthetic [ compound ] differ much possible order > affixation correspond vp \" , ( 2 ) theory > simply follow vp order . > > language cite , support theory ( 1 ) mostly > language relatively recently change order verb > object , order compound , e . g . germanic > language list ( v o < o v , compound ov ) finnish ( same ) . > similar example ( mirror image order change ) munda > language indium , word order change v o > o v , retain > old compound order vo , fact retain even finite > verb object incorporate ( compound ) . > > are example opposite order verb phrase compound > explain due lag morphological change > behind syntactic change ? > > david stampe > univ . hawaus ` > >\n",
      " \n",
      "\n",
      "\n",
      "dear colleague : week send query list ask fomral opposition between ' ' ' ' demonstrative ( june 4 , 6 . 772 , qs : ' ' , . . . ) . receive 26 response , necessary compile quick summary today away tokyo two week start tomorrow . original text query follow : present-day ' european ' language one set simple demonstrative opposition ( ) v . < > express help ( here ) < > : french cecus ' ' ce livre-cus ' book ' celum ' ' ce livre-l ` ' book ' swedish det ha \" r ' ' den ha \" r bilen ' car ' det da \" r ' ' den da \" r bilen ' car ' estonian siin ' ' maja siin ' house ' seal ' ' maja seal ' house ' sweidish - german dictionary ( stora tyska ordboken ) ( der hier ) ( der da ) colloquial ( familium \" r , umgangssprachlich ) german form conrrespond ( den ha \" r ) < den da \" r > , respectively . common demonstrative system ? incidentally , japanese rather sophisticate three-way distinction here : kono hon ' book ( here ) ' sono hon ' book ( ) , book ( under discussion ) ' ano hon ' book ( over ) ' ' m afraid convince student japanese extravagant even demonstrative . though paragraph intend allusion japanese tourist spend money oversea , quite few , both japanese non - japanese , seriously try convince japanese language ( sic ! ) means \" extravagant \" alone three-way distinction demonstrative . even draw attention existence language five-way distinction . thank example various demonstrative system send , point want discuss . perhap state explicitly interest morphology demonstrative pronoun / adjective . important french , instance , one basic demonstrative pronoun-adjective , . e . ( ce ) , morph-lexical level , speaker french optionally add element mean either ( here ) < > order finer distinction ( ce livre-cus , cette table-l ' ) . japanese , however , 's single basic demonstrative pronoun-adjective ( ce ) french : speaker japanese must alway choose one set three lexically distinct demonstrative form . big difference , puzzel many student estonian syntax class . here response direct relevance interest : - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - imagine post bite abbreviate , mention swedish demonstrative denna / detta / dessa den / det / de , case grammatically correct usual conversational speech ( \" den tiden , \" \" det aaret , \" \" de fraagorna \" ) . one expect danish norwegian similar regard swedish , unfortunately little information contribute . while danish both den / det / de plus option add \" der \" ( \" tag den bog , \" \" naer saa du de mennesker ? \" ; \" hvad er det der ? \" , \" jeg tager dem ( der ) \" ) , ' m certain whether usage quite same , , whether \" den der \" form predominate swedish . [ . . . ] certain dialect american english \" here \" \" , \" attest schoolteacher warn student those expression . ' re nonstandard regard uneducate usage , though suspect actually older dialect british descent acceptable . - - brian white ( bfwhite @ watson . ibm . com ) - - compund demonstrative indeed common own mother tongue , norwegian , believe ' scandinavian ' language , ie norwegian , danish swedish . feel feature colloquial speech , surprise ( formal ) write . fast speech distinction between two demonstrative tend lose , least own dialect ( bergen , western norway ) : den bilen - - - - ) 'd enner bilen ' ( car ) den der bilen - - - - ) 'd enner bilen ' ( car ) moreover , norwegian ( , believe , swedish + danish ) distinction : den bilen v denne bilen ( car v car ; masc . ) det huset v dette huset ( house v house ; neu . ) seem correspond closely / english , perfectly acceptable write speak norwegian . - - gisle andersen ( gisle . andersen @ eng . uib . ) - - native speaker , really ( der hier ) even colloquial , ( der da ) possible , likely contrast < der dort > , imply ( der da ) along < > < > ! general : alway problem native speaker german acquire / distinction , draw same boundary . maybe , formal ( term register ) : ( diese ) ( ) < jene > ( ) - - least translation ( german / english dictionary advise - never trust dictionary ) . actually , ( jene ) much , along formal speech maybe even old - fashion . - - gertraud benke ( gertraud @ leland . stanford . edu ) - - english colloquially , esp . black eng . vernacular , uses ' here ' ' . ' ' book here ' vs . ' book ' sounds perfectly normal , while ' here book ' ' book ' sound mostly american english south-east portion u . s . - - tim beasley ( tbeasley @ uclum . edu ) - - interest many dialect english ( appalachian us , therefore british dialect ) similar opposition one ' re talk : here dog dog one demonstrative , \" here \" \" \" seem relic old germanic usage . - - jame kirchner ( jpkirchner @ aol . com ) - - dialect british english ( ' m exclude variety n't enough ) ' here ' ' ' perfectly acceptable eg ' here postcard send ' ' pick bucket ' normal dialect - - david britain ( dbritain @ essex . ac . uk ) - - another funny case . colloquial english , \" here x \" \" x \" . greek , \" afto edho \" ( usually pronounce \" aftodho \" ) \" ekino ekus \" ( \" ekinokus \" ) same mean . ( \" dh \" = postdental fricative ) - - stavro macraki ( macraki @ osf . org ) - - interestingly , afrikaans , dutch - base creole , develop ' hierdie ' ( litt . ' here-that ' ) ' ' , wherea dutch itself system , simply 'd eze ' ' ' 'd ie ' ' ' . - - henk wolf ( h . . y . wolf @ stud . let . ruu . nl ) - - sure understand question correctly , italian ( northern italian least ) questo quus - - questo qua ( here ) instead \" questo \" quello lus ' - - quello la ' ( ) instead \" quello \" both colloquial form . cannot really whether part italy . - - anna mazzoldus ( mazzoldus @ iol . ie ) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - seem few execption ( italian dialect , greek ) , phenomenon seem characteristic germanic language language through strong germanic influence ( french , estonian ) . note incidentally finnish , genetically closely relate estonian , japanese side , similar split seem exist among romance language . interest ? example \" richer \" demonstrative system . interest those datum , please ask copy file contain response unedit form . hearty thanks follow respond query : philippe l . valiquette ( phlcvali @ vm1 . ulaval . ca ) gertraud benke ( gertraud @ leland . stanford . edu ) brian white ( bfwhite @ watson . ibm . com ) tim beasley ( tbeasley @ uclum . edu ) adriano paolo palma ( pyapp @ sun22 . ccunix . ccu . edu . tw ) jame kirchner ( jpkirchner @ aol . com ) eugene loo ( eugene . loo @ sil . org ) murat kural ( izzyfk6 @ mvs . oac . ucla . edu ) derek gowlett ( gowlett @ beattie . uct . ac . za ) jeff allen ( jhallen @ indiana . edu ) merce ( prat @ cogscus . ed . ac . uk ) nino ( n . vessellum @ agora . stm . ) david beck ( djbeck @ uvvm . uvic . ca ) debra r west / markell ( markell @ afterlife . ncsc . mil ) anna mazzoldus ( mazzoldus @ iol . ie ) stavro macraki ( macraki @ osf . org ) gisle andersen ( gisle . andersen @ eng . uib . ) david britain ( dbritain @ essex . ac . uk ) henk wolf ( h . . y . wolf @ stud . let . ruu . nl ) kiyoko takahashus ( gc610817 @ netserv . chulum . ac . th ) philippe mennecier ( ferry @ cimrs1 . mnhn . fr ) david parkinson ( dp11 @ cornell . edu ) anton sherwood ( dasher @ netcom . com ) ( nebiye . kurtboeke @ art . monash . edu . au ) kirk belnap ( belnapk @ yvax . byu . edu ) geoffrey s . nathan ( geoffn @ siu . edu ) ( 09 : 30 jst june 8 , 1995 ) best wish kazuto kazuto matsumura kmatsum @ tooyoo . l . u-tokyo . ac . jp - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - institute cross - cultural study ( tooyoo gengo ) faculty letter , university tokyo hongo 7 - 3 - 1 , bunkyo - ku , tokyo 113 japan tel . + 81 - 3-5800 - 3754 fax : + 81 - 3-5800 - 3740 , 5803-2784 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for sen in final['Emails'].values:\n",
    "    if(len(re.findall('<.*?>', sen))):\n",
    "        print(sen,\"\\n\\n\")\n",
    "        i += 1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sno = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanpunc(sentence):\n",
    "    '''This function cleans all the punctuation or special characters from a given sentence'''\n",
    "    cleaned = re.sub(r'[?|@|!|^|%|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(series):\n",
    "    '''The function takes a Pandas Series object containing text in all the cells\n",
    "       And performs following Preprocessing steps on each cell:\n",
    "       1. Clean text from html tags\n",
    "       2. Clean text from punctuations and special characters\n",
    "       3. Retain only non-numeric Latin characters with lenght > 2\n",
    "       4. Remove stopwords from the sentence\n",
    "       5. Apply stemming to all the words in the sentence\n",
    "       \n",
    "       Return values:\n",
    "       1. final_string - List of cleaned sentences\n",
    "       2. list_of_sent - List of lists which can be used as input to the W2V model'''\n",
    "    \n",
    "    i = 0\n",
    "    str1=\" \"\n",
    "    final_string = []    ## This list will contain cleaned sentences\n",
    "    list_of_sent = []    ## This is a list of lists used as input to the W2V model at a later stage\n",
    "    \n",
    "    ## Creating below lists for future use\n",
    "    all_positive_words=[] # store words from hamp mails\n",
    "    all_negative_words=[] # store words from spam mails here\n",
    "    \n",
    "    \n",
    "    for sent in series.values:\n",
    "        ## \n",
    "        filtered_sent = []\n",
    "        list_of_sent = []\n",
    "        sent = cleanpunc(sent)    ## Clean the punctuations and special characters\n",
    "        ## Sentences are cleaned and words are handled individually\n",
    "        for cleaned_words in sent.split():\n",
    "            ## Only consider non-numeric words with length at least 3\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words) > 2)):\n",
    "                ## Only consider words which are not stopwords and convert them to lowet case\n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    ## Apply snowball stemmer and add them to the filtered_sent list\n",
    "                    s = (sno.stem(cleaned_words.lower()))#.encode('utf-8')\n",
    "                    filtered_sent.append(s)    ## This contains all the cleaned words for a sentence\n",
    "                    if (final['lable'].values)[i] == 1:\n",
    "                        all_positive_words.append(s) #list of all words used to describe ham mails\n",
    "                    if(final['lable'].values)[i] == 0:\n",
    "                        all_negative_words.append(s) #list of all words used to describe spam mails\n",
    "        ## Below list is a list of lists used as input to W2V model later\n",
    "        list_of_sent.append(filtered_sent)\n",
    "        ## Join back all the words belonging to the same sentence\n",
    "        str1 = \" \".join(filtered_sent)\n",
    "        ## Finally add the cleaned sentence in the below list\n",
    "        final_string.append(str1)\n",
    "        #print(i)\n",
    "        i += 1\n",
    "    return final_string, list_of_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slur . . . mean , sir : armey 's slip slip , slip sort represent compete plan , one ask , why compete plan ? phonological similarity ( \" similarity \" aristotean catch-all ) [ / fraenk / v . / faeg / ] something bernie baar 's \" unintentional \" pun , clearly indicate something bite raw phonological similarity . non-phonological , compete plan notion bring sort interpretive issue concern why armey something painfully abusive \" mind \" produce \" fag . \" \" mind , \" ( point during on-line speech ) anything typically volitional intentional . tricky issue .\n",
      " \n",
      "\n",
      "\n",
      "across mail 12 re : punctuation . email punctuation discussion group . subscription address ( far remember ) : punct-l @ milwaukee . tec . wus . us hope . caroline ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ caroline ann leathem ~ ~ msc . speech language process ~ ~ edinburgh university ~ ~ ~ ~ email : cleathem @ ling . ed . ac . uk ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\n",
      " \n",
      "\n",
      "\n",
      "subject : begin begin begin groundfloor something unprecedent . miss profite microsoft 's stellar rise . . . . . . profite satellite tv explosion . . . . . . profite internet phenomenon . . . watch real opportunity after real opportunity pass fortune . . . ' ve hand another chance . one mother opportunity . invite listen learn product decade . . . . . . why our exclusive rights fortune . toll free 1-888 - 625-8106 ( 24 hour )\n",
      " \n",
      "\n",
      "\n",
      "nice true democracy try reach agreement phonetic symbol , stemburger suggest . war too important matter leave general , choose standardize set symbol n't leave phonetician . international phonetic association alway recognize . fully conscious fact ipa symbol wide variety . 1989 kiel convention , first major revision almost 50 , great deal discussion remember our ' customer ' , one phonetician put . ( despite comment contrary participant discussion ) change since small change affect comparatively few user alphabet , largely belief important alphabet remain stable possible . stemburger organize kind referendum , luck . note suggest lsa appropriate body u . s . , although mention ashla ( american speech hear language association ) interest group officially adopt ipa . membership much larger lsa . asa ( acoustical society america ) another group many member interest phonetic symbol . the1989 ipa kiel convention open , include member organization mention stemburger , include lsa , ashla , asa , sil , none participant , course , speak officially organization . convention publicize paper language , paper morri halle ever co-author . really international collaboration . agree symbol difficult everyone same unit measure weight distance . response previous suggestion interest choice phonetic symbol join international phonetic association , receive inquiry . form journal international phonetic association ( member receive - - university library + + ) . really need send name address , plus check $ 25 # 13 sterl ( request charge access / mastercharge / visa / eurocard ) annual dues : secretariat , ipa linguistic phonetic univeristy leed leed , ls2 9jt , u . k . peter ladefoge\n",
      " \n",
      "\n",
      "\n",
      "read research literature slip tongue scan both normal aphasic corpus , hard believe much discuss slip linguistic tho , sense , freudian . bob wachal\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in final['Emails'].iloc[:5].values:\n",
    "    print(x,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slur mean sir armey slip slip slip sort repres compet plan one ask compet plan phonolog similar similar aristotean fraenk faeg someth berni baar unintent pun clear indic someth bite raw phonolog similar compet plan notion bring sort interpret issu concern armey someth pain abus mind produc fag mind point speech anyth typic volit intent tricki issu \n",
      "\n",
      "\n",
      "across mail punctuat email punctuat discuss group subscript address far rememb milwauke tec wus hope carolin carolin ann leathem msc speech languag process edinburgh univers email cleathem ling \n",
      "\n",
      "\n",
      "subject begin begin begin groundfloor someth unpreced miss profit microsoft stellar rise profit satellit explos profit internet phenomenon watch real opportun real opportun pass fortun hand anoth chanc one mother opportun invit listen learn product decad exclus right fortun toll free hour \n",
      "\n",
      "\n",
      "nice true democraci tri reach agreement phonet symbol stemburg suggest war import matter leav general choos standard set symbol leav phonetician intern phonet associ alway recogn fulli conscious fact ipa symbol wide varieti kiel convent first major revis almost great deal discuss rememb custom one phonetician put despit comment contrari particip discuss chang sinc small chang affect compar user alphabet larg belief import alphabet remain stabl possibl stemburg organ kind referendum luck note suggest lsa appropri bodi although mention ashla american speech hear languag associ interest group offici adopt ipa membership much larger lsa asa acoust societi america anoth group mani member interest phonet symbol ipa kiel convent open includ member organ mention stemburg includ lsa ashla asa sil none particip cours speak offici organ convent public paper languag paper morri hall ever realli intern collabor agre symbol difficult everyon unit measur weight distanc respons previous suggest interest choic phonet symbol join intern phonet associ receiv inquiri form journal intern phonet associ member receiv univers librari realli need send name address plus check sterl request charg access mastercharg visa eurocard annual due secretariat ipa linguist phonet univeristi leed leed peter ladefog \n",
      "\n",
      "\n",
      "read research literatur slip tongu scan normal aphas corpus hard believ much discuss slip linguist tho sens freudian bob wachal \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_string, list_of_sent = preprocessing(final['Emails'].iloc[:5])\n",
    "for x in final_string:\n",
    "    print(x,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_string, list_of_sent = preprocessing(final['Emails'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "962"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emails</th>\n",
       "      <th>lable</th>\n",
       "      <th>CleanedMails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slur . . . mean , sir : armey 's slip slip , s...</td>\n",
       "      <td>1</td>\n",
       "      <td>slur mean sir armey slip slip slip sort repres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>across mail 12 re : punctuation . email punctu...</td>\n",
       "      <td>1</td>\n",
       "      <td>across mail punctuat email punctuat discuss gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject : begin begin begin groundfloor someth...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject begin begin begin groundfloor someth u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nice true democracy try reach agreement phonet...</td>\n",
       "      <td>1</td>\n",
       "      <td>nice true democraci tri reach agreement phonet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>read research literature slip tongue scan both...</td>\n",
       "      <td>1</td>\n",
       "      <td>read research literatur slip tongu scan normal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Emails  lable  \\\n",
       "0  slur . . . mean , sir : armey 's slip slip , s...      1   \n",
       "1  across mail 12 re : punctuation . email punctu...      1   \n",
       "2  subject : begin begin begin groundfloor someth...      0   \n",
       "3  nice true democracy try reach agreement phonet...      1   \n",
       "4  read research literature slip tongue scan both...      1   \n",
       "\n",
       "                                        CleanedMails  \n",
       "0  slur mean sir armey slip slip slip sort repres...  \n",
       "1  across mail punctuat email punctuat discuss gr...  \n",
       "2  subject begin begin begin groundfloor someth u...  \n",
       "3  nice true democraci tri reach agreement phonet...  \n",
       "4  read research literatur slip tongu scan normal...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['CleanedMails']=final_string\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Emails.sqlite')\n",
    "c=conn.cursor()\n",
    "final.to_sql('Emails', conn, if_exists='replace')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
